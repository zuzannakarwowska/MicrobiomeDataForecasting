{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "973bb3ef-bce5-4118-808c-ac1c90147890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 12:16:09.984236: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-10 12:16:09.984283: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import interpolate \n",
    "import random\n",
    "\n",
    "import keras.backend as K\n",
    "import skbio\n",
    "from io import StringIO\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5054a9-8a09-49fd-a8b4-7c8363d395e0",
   "metadata": {},
   "source": [
    "As this is implemented as a loss and we minimize the loss during training the sign is inverted, so that when you minimize the loss (towards -1), the actual similarity is maximized towards 1.\n",
    "\n",
    "if we use it as metric it will converge to 1, if we use it as loss it will fo towards -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51aaeaf9-3a2b-4e1e-be6d-314eefb8d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('rarefied_interpolated_male_feces copy.tsv',\n",
    "                  sep='\\t', header = [1], index_col =[0])\n",
    "df = df.T\n",
    "df = df.head(402)\n",
    "\n",
    "X_train = df.sample(350, random_state = 42)\n",
    "X_test = df[~df.index.isin (X_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "38d2e059-4baf-49a3-8e8a-84110bde1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "normalized_data = scaler.fit_transform(np.log(1+X_train))\n",
    "normalized_test = scaler.transform(np.log(1+X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "db41d400-10e4-4196-91b4-c12d5dc29292",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f46acb-a4dd-489b-96cd-85237f4a5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomized model\n",
    "def model_dropout(h_neurons, dropout, l_neurons):\n",
    "    \n",
    "    #SGD\n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.8\n",
    "    \n",
    "    sgd = SGD(lr=learning_rate, momentum=momentum, nesterov=True)\n",
    "\n",
    "    # create model\n",
    "    input_size = x.shape[1]\n",
    "    input_data = Input(shape=(input_size,))\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #encoder layer #1\n",
    "    model.add(Dense(h_neurons, activation='relu', input_dim=input_size))#, kernel_regularizer=regularizers.l2(l2_reg))) \n",
    "\n",
    "    ######## latent layer #########\n",
    "    model.add(Dense(l_neurons, activation='relu'))\n",
    "    \n",
    "    #dropout layer\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    #batch norm layer\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    #decoder layer #1\n",
    "    model.add(Dense(h_neurons, activation='relu'))#, kernel_regularizer=regularizers.l2(l2=l2_reg))) \n",
    "    \n",
    "    #dropout layer\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    #batch norm layer\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(input_size, activation='sigmoid')) #output as we normalized data between 0 and 1\n",
    "    \n",
    "    # Compile model\n",
    "    #model.compile(loss='mae', optimizer=sgd)\n",
    "    cosine_loss = CosineSimilarity()\n",
    "    log_loss = tf.keras.losses.MeanSquaredLogarithmicError() #best 0\n",
    "    model.compile(loss=log_loss, optimizer='Adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "#build model\n",
    "model = KerasRegressor(build_fn=model_dropout, verbose=0)\n",
    "\n",
    "#params\n",
    "batch_size = [8, 16, 32]\n",
    "epochs = [15]\n",
    "h_neurons = [126, 252, 504]\n",
    "l_neurons = [32, 64, 126]\n",
    "dropout = [0.2, 0.5, 0.7]\n",
    "#l2_reg = [0, 0.01, 0.1]\n",
    "\n",
    "#param grid\n",
    "param_grid = dict(\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    h_neurons = h_neurons,\n",
    "    l_neurons = l_neurons,\n",
    "    dropout = dropout\n",
    ")\n",
    "\n",
    "#validation\n",
    "kfld = KFold(n_splits=3,\n",
    "             shuffle=True,\n",
    "             random_state=seed\n",
    "            )\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model,\n",
    "                          cv=kfld,\n",
    "                          param_distributions=param_grid, \n",
    "                          verbose=20,\n",
    "                          n_iter=10,\n",
    "                          n_jobs=1\n",
    "                         )\n",
    "\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=epochs_to_wait_for_improve)\n",
    "\n",
    "grid_result = grid.fit(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e24c60-ac70-4495-b8de-b188916de9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b522a2-5d56-47be-9a6a-67a414bd311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_params_['l_neurons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246578d9-20f7-47b7-a201-fc7b8057cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_name, metric in self.metrics_dict.items():\n",
    "    logs[f'{prefix}_{metric_name} = np.array(metric(...))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8d48cc1c-cd49-4c58-a9bc-6cb2d1b3e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, validation_data, scaler, prefix = 'val'):\n",
    "        self.validation_data = validation_data #podpinamy validation data\n",
    "        self.scaler = scaler\n",
    "        self.prefix = prefix\n",
    "        \n",
    "        metrics_dict = {}\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        \n",
    "        predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "        targ = self.validation_data[1]\n",
    "        \n",
    "        predict_denorm = np.exp(scaler.inverse_transform(predict)) - 1\n",
    "        target_denrom = np.exp(scaler.inverse_transform(targ)) - 1\n",
    "        \n",
    "        logs[f'{self.prefix}_cosine_distance'] = np.array([distance.cosine(target_denrom[i], predict_denorm[i]) for i in range(target_denrom.shape[0])]).mean()\n",
    "        logs[f'{self.prefix}_bray_curtis'] = np.array([distance.braycurtis(target_denrom[i], predict_denorm[i]) for i in range(target_denrom.shape[0])]).mean()\n",
    "        \n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2f9e2d-c2fb-4c0a-8f22-a54769815a36",
   "metadata": {},
   "source": [
    "### model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8590c267-bd1a-477a-a470-0b18d7ef07f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.9432 - val_loss: 0.8000 - val_cosine_distance: 0.0902 - val_bray_curtis: 0.2977 - train_cosine_distance: 0.0909 - train_bray_curtis: 0.3005\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.8537 - val_loss: 0.7468 - val_cosine_distance: 0.0930 - val_bray_curtis: 0.2575 - train_cosine_distance: 0.0858 - train_bray_curtis: 0.2529\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.7828 - val_loss: 0.7184 - val_cosine_distance: 0.0804 - val_bray_curtis: 0.2344 - train_cosine_distance: 0.0734 - train_bray_curtis: 0.2264\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.7183 - val_loss: 0.7025 - val_cosine_distance: 0.0788 - val_bray_curtis: 0.2447 - train_cosine_distance: 0.0777 - train_bray_curtis: 0.2340\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6585 - val_loss: 0.6852 - val_cosine_distance: 0.0707 - val_bray_curtis: 0.2384 - train_cosine_distance: 0.0646 - train_bray_curtis: 0.2116\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "input_size = normalized_data.shape[1]\n",
    "input_data = tf.keras.Input(shape=(input_size,))\n",
    "\n",
    "encoded = tf.keras.layers.Dense(504, activation='relu')(input_data)\n",
    "encoded = tf.keras.layers.Dense(252, activation='relu')(input_data)\n",
    "\n",
    "encoded = tf.keras.layers.Dense(64)(encoded) ##latent, linear act\n",
    "\n",
    "#decoded = layers.Dropout(grid_result.best_params_['dropout'])(decoded)\n",
    "decoded = tf.keras.layers.Dense(252, activation='relu')(encoded)\n",
    "decoded = tf.keras.layers.Dense(504, activation='relu')(decoded)\n",
    "\n",
    "#output layer\n",
    "decoded = tf.keras.layers.Dense(input_size, activation='linear')(decoded)\n",
    "\n",
    "# Compile model\n",
    "autoencoder = tf.keras.Model(input_data, decoded)\n",
    "\n",
    "\n",
    "autoencoder.compile(\n",
    "    #loss=tf.keras.losses.MeanSquaredLogarithmicError(),\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    \n",
    "    optimizer='Adam'\n",
    ")\n",
    "\n",
    "metrics = Metrics(validation_data = (normalized_test, normalized_test), scaler=scaler, prefix='val')\n",
    "train_metrics = Metrics(validation_data = (normalized_data, normalized_data), scaler=scaler, prefix = 'train')\n",
    "\n",
    "\n",
    "test_result = autoencoder.fit(\n",
    "    normalized_data, normalized_data,\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    validation_data=(normalized_test, normalized_test),\n",
    "    callbacks = [metrics, train_metrics]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "464b455c-9963-475f-97bb-85c77af8d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_loss_df = pd.DataFrame.from_dict(test_result.history)\n",
    "train_val_loss_df['epochs'] = train_val_loss_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "84667968-61de-4cda-a289-6bf7c0c733e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_cosine_distance</th>\n",
       "      <th>val_bray_curtis</th>\n",
       "      <th>train_cosine_distance</th>\n",
       "      <th>train_bray_curtis</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.943173</td>\n",
       "      <td>0.800041</td>\n",
       "      <td>0.090179</td>\n",
       "      <td>0.297666</td>\n",
       "      <td>0.090887</td>\n",
       "      <td>0.300489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.853669</td>\n",
       "      <td>0.746791</td>\n",
       "      <td>0.093016</td>\n",
       "      <td>0.257505</td>\n",
       "      <td>0.085810</td>\n",
       "      <td>0.252944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.782791</td>\n",
       "      <td>0.718443</td>\n",
       "      <td>0.080393</td>\n",
       "      <td>0.234396</td>\n",
       "      <td>0.073379</td>\n",
       "      <td>0.226374</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.718305</td>\n",
       "      <td>0.702507</td>\n",
       "      <td>0.078807</td>\n",
       "      <td>0.244654</td>\n",
       "      <td>0.077657</td>\n",
       "      <td>0.234014</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.658464</td>\n",
       "      <td>0.685150</td>\n",
       "      <td>0.070747</td>\n",
       "      <td>0.238409</td>\n",
       "      <td>0.064608</td>\n",
       "      <td>0.211648</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss  val_cosine_distance  val_bray_curtis  \\\n",
       "0  0.943173  0.800041             0.090179         0.297666   \n",
       "1  0.853669  0.746791             0.093016         0.257505   \n",
       "2  0.782791  0.718443             0.080393         0.234396   \n",
       "3  0.718305  0.702507             0.078807         0.244654   \n",
       "4  0.658464  0.685150             0.070747         0.238409   \n",
       "\n",
       "   train_cosine_distance  train_bray_curtis  epochs  \n",
       "0               0.090887           0.300489       0  \n",
       "1               0.085810           0.252944       1  \n",
       "2               0.073379           0.226374       2  \n",
       "3               0.077657           0.234014       3  \n",
       "4               0.064608           0.211648       4  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b3d0f567-b872-44eb-b349-0f2dd591834a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_cosine_distance</th>\n",
       "      <th>val_bray_curtis</th>\n",
       "      <th>train_cosine_distance</th>\n",
       "      <th>train_bray_curtis</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950177</td>\n",
       "      <td>1.296157</td>\n",
       "      <td>0.083852</td>\n",
       "      <td>0.283860</td>\n",
       "      <td>0.079819</td>\n",
       "      <td>0.281080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.884891</td>\n",
       "      <td>1.246577</td>\n",
       "      <td>0.072751</td>\n",
       "      <td>0.246030</td>\n",
       "      <td>0.062970</td>\n",
       "      <td>0.236884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.813834</td>\n",
       "      <td>1.210798</td>\n",
       "      <td>0.065849</td>\n",
       "      <td>0.238871</td>\n",
       "      <td>0.053123</td>\n",
       "      <td>0.220401</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.736258</td>\n",
       "      <td>1.179414</td>\n",
       "      <td>0.058096</td>\n",
       "      <td>0.224838</td>\n",
       "      <td>0.041988</td>\n",
       "      <td>0.201863</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.668937</td>\n",
       "      <td>1.166469</td>\n",
       "      <td>0.054968</td>\n",
       "      <td>0.219866</td>\n",
       "      <td>0.040730</td>\n",
       "      <td>0.198197</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss  val_cosine_distance  val_bray_curtis  \\\n",
       "0  0.950177  1.296157             0.083852         0.283860   \n",
       "1  0.884891  1.246577             0.072751         0.246030   \n",
       "2  0.813834  1.210798             0.065849         0.238871   \n",
       "3  0.736258  1.179414             0.058096         0.224838   \n",
       "4  0.668937  1.166469             0.054968         0.219866   \n",
       "\n",
       "   train_cosine_distance  train_bray_curtis  epochs  \n",
       "0               0.079819           0.281080       0  \n",
       "1               0.062970           0.236884       1  \n",
       "2               0.053123           0.220401       2  \n",
       "3               0.041988           0.201863       3  \n",
       "4               0.040730           0.198197       4  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992338ed-591a-4dc1-83cc-72f8d48d31ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.lineplot(x = train_val_loss_df['epochs'], y = train_val_loss_df['loss'], color = 'black')\n",
    "sns.scatterplot(x = train_val_loss_df['epochs'], y = train_val_loss_df['loss'], color = 'black')\n",
    "\n",
    "sns.lineplot(x = train_val_loss_df['epochs'], y = train_val_loss_df['val_loss'], color = 'orange')\n",
    "sns.scatterplot(x = train_val_loss_df['epochs'], y = train_val_loss_df['val_loss'], color = 'orange')\n",
    "#plt.title('cosine similarity on train and test data')\n",
    "#plt.savefig('AE_cosine_sim/model1_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f9ab0a-48e0-4964-994b-a36b18887e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.lineplot(x = train_val_loss_df['epochs'], y = train_val_loss_df['cosine_similarity'], color = 'black')\n",
    "sns.scatterplot(x = train_val_loss_df['epochs'], y = train_val_loss_df['cosine_similarity'], color = 'black')\n",
    "\n",
    "sns.lineplot(x = train_val_loss_df['epochs'], y = train_val_loss_df['val_cosine_similarity'], color = 'orange')\n",
    "sns.scatterplot(x = train_val_loss_df['epochs'], y = train_val_loss_df['val_cosine_similarity'], color = 'orange')\n",
    "plt.title('cosine similarity on train and test data')\n",
    "#plt.savefig('AE_cosine_sim/model1_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea4402-60e6-47a8-8c31-e7f9c47851c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.lineplot(x = train_val_loss_df['epochs'], y = train_val_loss_df['root_mean_squared_error'], color = 'black')\n",
    "sns.scatterplot(x = train_val_loss_df['epochs'], y = train_val_loss_df['root_mean_squared_error'], color = 'black')\n",
    "\n",
    "sns.lineplot(x = train_val_loss_df['epochs'], y = train_val_loss_df['val_root_mean_squared_error'], color = 'orange')\n",
    "sns.scatterplot(x = train_val_loss_df['epochs'], y = train_val_loss_df['val_root_mean_squared_error'], color = 'orange')\n",
    "plt.title('root_mean_squared_error on train and test data')\n",
    "#plt.savefig('AE_cosine_sim/model1_loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a667fa0b-93a0-437e-a592-3fd0753d664c",
   "metadata": {},
   "source": [
    "custom unifrac loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1631f7-ff8b-4a9b-8ebe-dc5254cf0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import skbio\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7cdc8f-3fa6-4ffd-8383-18bba1408163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unifrac_loss(y_true, y_reconstructed):\n",
    "    \n",
    "    tree_file = 'tree.nwk'\n",
    "    tree = skbio.tree.TreeNode.read(tree_file)\n",
    "    \n",
    "    loss = skbio.diversity.beta.unweighted_unifrac(y_true,\n",
    "                                                   y_reconstructed,\n",
    "                                                   otu_ids = df.columns,\n",
    "                                                   tree=tree\n",
    "                                                  )\n",
    "    loss = K.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f662b-7fdb-4f67-8e7c-568cf374d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "input_size = normalized_data.shape[1]\n",
    "input_data = Input(shape=(input_size,))\n",
    "\n",
    "encoded = layers.Dense(504, activation='relu')(input_data)\n",
    "\n",
    "encoded = layers.Dense(64, activation = 'relu')(encoded) ##latent\n",
    "\n",
    "decoded = layers.Dense(504, activation='relu')(encoded)\n",
    "#output layer\n",
    "decoded = layers.Dense(input_size, activation='sigmoid')(decoded)\n",
    "\n",
    "# Compile model\n",
    "autoencoder = Model(input_data, decoded)\n",
    "\n",
    "loss_fn = CosineSimilarity()\n",
    "autoencoder.compile(\n",
    "    loss=unifrac_loss,\n",
    "    optimizer='Adam'\n",
    ")\n",
    "\n",
    "test_result = autoencoder.fit(\n",
    "    x, x,\n",
    "    epochs=2,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    validation_data=(x, x)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_ae",
   "language": "python",
   "name": "deep_ae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
